import os
import pandas as pd
import numpy as np
import h3
from scipy.spatial import cKDTree
from datetime import datetime, timedelta
from utils_h3 import index_files, sample_multiband_robust
from config import FILL_CONFIG, DATA_PROCESSED, DATA_RAW

# ---------------------------------------------------------
# CORE LOGIC: EXTRACT
# ---------------------------------------------------------
def extract_generic(spec_name, spec_config, h3_data, raw_root_dir):
    h3_ids, point_groups, h3_geoms = h3_data
    input_dir = os.path.join(raw_root_dir, spec_config["folder"])
    col_name = spec_config["col_name"]
    
    file_map = index_files(input_dir)
    if not file_map:
        return pd.DataFrame()

    records = []
    sorted_items = sorted(file_map.items())
    
    # print(f"   ‚è≥ Extracting {spec_name}...") 
    
    for (year, month), tif_path in sorted_items:
        # L·∫•y m·∫´u d·ªØ li·ªáu (Robust sampling)
        vals, _ = sample_multiband_robust(tif_path, point_groups, h3_geoms, n_random=15)
        num_days = len(vals[0]) if vals and vals[0] else 0
        
        for d in range(num_days):
            current_date = datetime(year, month, 1) + timedelta(days=d)
            date_str = current_date.strftime("%Y-%m-%d")
            
            for i, h3_id in enumerate(h3_ids):
                records.append({
                    "h3_index": h3_id,
                    "date": date_str,
                    col_name: vals[i][d]
                })
                
    return pd.DataFrame(records)

# ---------------------------------------------------------
# CORE LOGIC: SPATIAL FILL (K-RING)
# ---------------------------------------------------------
def fill_spatial_generic(df, col_name):
    if df.empty: return df
    
    # X·ª≠ l√Ω gi√° tr·ªã r√°c -9999 th√†nh NaN
    df[col_name] = df[col_name].replace(-9999.0, np.nan)
    
    # N·∫øu kh√¥ng c√≤n thi·∫øu th√¨ tr·∫£ v·ªÅ lu√¥n
    if not df[col_name].isna().any():
        return df

    h3_ids = df["h3_index"].unique()
    dates = df["date"].unique()
    max_k = FILL_CONFIG["MAX_K"]
    min_nei = FILL_CONFIG["MIN_NEI"]
    
    # Precompute k-ring cho t·∫•t c·∫£ c√°c √¥
    # L∆∞u √Ω: h3 v4 d√πng grid_disk, v3 d√πng k_ring. Code h·ªó tr·ª£ v4.
    try:
        k_ring_map = {h: {k: list(h3.grid_disk(h, k)) for k in range(1, max_k + 1)} for h in h3_ids}
    except AttributeError:
        k_ring_map = {h: {k: list(h3.k_ring(h, k)) for k in range(1, max_k + 1)} for h in h3_ids}
    
    # T·∫°o map d·ªØ li·ªáu ƒë·ªÉ tra c·ª©u nhanh
    val_map = {(r.h3_index, r.date): getattr(r, col_name) for r in df.itertuples(index=False)}
    
    updates = []
    
    for date in dates:
        for h in h3_ids:
            key = (h, date)
            val = val_map.get(key)
            # N·∫øu ƒë√£ c√≥ d·ªØ li·ªáu th√¨ b·ªè qua
            if pd.notna(val): continue
            
            found_val = None
            for k in range(1, max_k + 1):
                neighs = k_ring_map.get(h, {}).get(k, [])
                valid_vals = [val_map.get((n, date)) for n in neighs if pd.notna(val_map.get((n, date)))]
                
                if len(valid_vals) >= min_nei:
                    found_val = sum(valid_vals) / len(valid_vals)
                    break 
            
            if found_val is not None:
                val_map[key] = found_val
                updates.append((h, date, found_val))

    # C·∫≠p nh·∫≠t l·∫°i DataFrame t·ª´ map
    # (C√°ch n√†y nhanh h∆°n l√† g√°n t·ª´ng d√≤ng)
    df[col_name] = [val_map.get((r.h3_index, r.date)) for r in df.itertuples()]
    
    return df

# ---------------------------------------------------------
# CORE LOGIC: FINAL FILL (NEAREST NEIGHBOR)
# ---------------------------------------------------------
def fill_final_nearest(df, col_name):
    """
    Chi·∫øn l∆∞·ª£c c·ª©u h·ªô cu·ªëi c√πng (Last Resort):
    T√¨m 1 √¥ h√†ng x√≥m g·∫ßn nh·∫•t (Nearest Neighbor) tr√™n to√†n b·∫£n ƒë·ªì c√≥ d·ªØ li·ªáu
    v√† sao ch√©p d·ªØ li·ªáu sang √¥ b·ªã thi·∫øu.
    D√πng cho c√°c ƒë·∫£o xa ho·∫∑c v√πng m√¢y qu√° l·ªõn m√† Spatial Fill (K-Ring) b√≥ tay.
    """
    # 1. Ki·ªÉm tra xem c√≤n thi·∫øu kh√¥ng
    missing_mask = df[col_name].isna()
    if not missing_mask.any():
        return df
        
    print(f"   üîß [Final Fill] Found {missing_mask.sum()} isolated cells. Running Nearest Neighbor...")

    # 2. T√°ch d·ªØ li·ªáu T·ªët (Ngu·ªìn) v√† X·∫•u (ƒê√≠ch)
    bad_ids = df[missing_mask]["h3_index"].unique()
    all_ids = df["h3_index"].unique()
    # Good ids l√† nh·ªØng √¥ KH√îNG n·∫±m trong bad_ids
    good_ids = list(set(all_ids) - set(bad_ids))

    if not good_ids: 
        return df

    # 3. X√¢y d·ª±ng c√¢y t√¨m ki·∫øm kho·∫£ng c√°ch (KDTree)
    # H·ªó tr·ª£ c·∫£ H3 v3 v√† v4
    try:
        good_coords = [h3.cell_to_latlng(h) for h in good_ids]
        bad_coords = [h3.cell_to_latlng(h) for h in bad_ids]
    except AttributeError:
        good_coords = [h3.h3_to_geo(h) for h in good_ids]
        bad_coords = [h3.h3_to_geo(h) for h in bad_ids]
    
    tree = cKDTree(good_coords)
    # T√¨m 1 ƒëi·ªÉm g·∫ßn nh·∫•t (k=1)
    dists, indices = tree.query(bad_coords, k=1)

    # 4. Map √¥ X·∫•u -> √¥ T·ªët g·∫ßn nh·∫•t
    rescue_map = {bad_ids[i]: good_ids[indices[i]] for i in range(len(bad_ids))}

    # 5. ƒêi·ªÅn d·ªØ li·ªáu
    # T·∫°o dictionary tra c·ª©u d·ªØ li·ªáu t·ªët: {(h3, date): value}
    df_good = df[df["h3_index"].isin(good_ids)]
    val_map = dict(zip(zip(df_good["h3_index"], df_good["date"]), df_good[col_name]))

    # C·∫≠p nh·∫≠t gi√° tr·ªã
    def get_rescue_val(row):
        if pd.isna(row[col_name]):
            source_h3 = rescue_map.get(row["h3_index"])
            if source_h3:
                return val_map.get((source_h3, row["date"]), np.nan)
        return row[col_name]

    df[col_name] = df.apply(get_rescue_val, axis=1)
    
    # Fill n·ªët c√°c l·ªó h·ªïng th·ªùi gian n·∫øu √¥ ngu·ªìn c≈©ng b·ªã thi·∫øu 1 v√†i ng√†y
    if df[col_name].isna().any():
         df[col_name] = df[col_name].interpolate(method='linear', limit_direction='both')

    return df

# ---------------------------------------------------------
# WORKER FUNCTION (Cho Multiprocessing)
# ---------------------------------------------------------
def process_single_dataset(args):
    """
    H√†m worker ch·∫°y tr√™n Process ri√™ng.
    Args: (key, spec, h3_data_bundle)
    """
    key, spec, h3_data_bundle = args
    print(f"üöÄ [Start] {key.upper()} processing...")
    
    try:
        # 1. Extract
        df = extract_generic(key, spec, h3_data_bundle, DATA_RAW)
        if df.empty:
            print(f"‚ö†Ô∏è [Skip] {key.upper()} - No data found.")
            return key
            
        # 2. Check Missing & Cleanup
        col_name = spec["col_name"]
        # Convert r√°c th√†nh NaN tr∆∞·ªõc khi check
        if col_name in df.columns:
            df[col_name] = df[col_name].replace(-9999.0, np.nan)
            nan_raw = df[col_name].isna().sum()
        else:
            nan_raw = 0
        
        # 3. Fill Strategy
        if nan_raw > 0:
            # B∆∞·ªõc A: Spatial Fill (H√†ng x√≥m l√¢n c·∫≠n)
            df = fill_spatial_generic(df, col_name)
            
            # B∆∞·ªõc B: Final Fill (H√†ng x√≥m g·∫ßn nh·∫•t to√†n c·ª•c - C·ª©u ƒë·∫£o xa)
            nan_remaining = df[col_name].isna().sum()
            if nan_remaining > 0:
                df = fill_final_nearest(df, col_name)
            
        # 4. Save
        out_path = os.path.join(DATA_PROCESSED, spec["output_file"])
        df.to_csv(out_path, index=False)
        print(f"‚úÖ [Done] {key.upper()} saved.")
        
    except Exception as e:
        print(f"‚ùå [Error] {key.upper()}: {e}")
        raise e
        
    return key


# ---------------------------------------------------------
# MERGE FUNCTION
# ---------------------------------------------------------
from config import DATA_SPECS, DATA_PROCESSED

def merge_all_datasets():
    """
    G·ªôp t·∫•t c·∫£ c√°c file CSV th√†nh ph·∫ßn (M∆∞a, Nhi·ªát, ·∫®m...) th√†nh 1 file t·ªïng.
    Join key: ['h3_index', 'date']
    """
    print("üîÑ [MERGE] B·∫Øt ƒë·∫ßu g·ªôp c√°c file d·ªØ li·ªáu...")
    
    # 1. T·∫≠p h·ª£p danh s√°ch file t·ª´ Config
    # Ch·ªâ l·∫•y nh·ªØng key c√≥ trong DATA_SPECS
    dfs = []
    
    for key, spec in DATA_SPECS.items():
        file_path = os.path.join(DATA_PROCESSED, spec["output_file"])
        
        if not os.path.exists(file_path):
            print(f"‚ö†Ô∏è [Warning] File kh√¥ng t·ªìn t·∫°i, b·ªè qua: {spec['output_file']}")
            continue
            
        print(f"   üìñ Reading {key}...")
        # ƒê·ªçc file, √©p ki·ªÉu h3_index v·ªÅ string ƒë·ªÉ tr√°nh l·ªói merge
        df = pd.read_csv(file_path, dtype={'h3_index': str})
        
        # ƒê·∫£m b·∫£o c·ªôt date ƒë√∫ng ƒë·ªãnh d·∫°ng
        # df['date'] = pd.to_datetime(df['date']) 
        
        # Set index l√† (h3_index, date) ƒë·ªÉ chu·∫©n b·ªã merge
        df = df.set_index(['h3_index', 'date'])
        dfs.append(df)
    
    if not dfs:
        print("‚ùå Kh√¥ng t√¨m th·∫•y file d·ªØ li·ªáu n√†o ƒë·ªÉ g·ªôp!")
        return

    # 2. Th·ª±c hi·ªán Merge (Join)
    # D√πng concat axis=1 s·∫Ω nhanh h∆°n merge t·ª´ng l·∫ßn
    print("   üîó Joining dataframes...")
    try:
        final_df = pd.concat(dfs, axis=1, join='outer')
        
        # Reset index ƒë·ªÉ ƒë∆∞a h3_index v√† date tr·ªü l·∫°i th√†nh c·ªôt
        final_df = final_df.reset_index()
        
        # 3. L∆∞u k·∫øt qu·∫£
        output_csv = os.path.join(DATA_PROCESSED, "FINAL_MERGED_DATASET.csv")
        # output_parquet = os.path.join(DATA_PROCESSED, "FINAL_MERGED_DATASET.parquet")
        
        print(f"   üíæ Saving to {output_csv}...")
        final_df.to_csv(output_csv, index=False)
        # final_df.to_parquet(output_parquet, index=False) # Khuy√™n d√πng Parquet n·∫øu file l·ªõn
        
        print(f"‚úÖ [DONE] ƒê√£ g·ªôp th√†nh c√¥ng! K√≠ch th∆∞·ªõc: {final_df.shape}")
        return final_df
        
    except Exception as e:
        print(f"‚ùå [Error] L·ªói khi g·ªôp file: {e}")
        return None